{"posts":[{"title":"VLDB 2024 OpAdviser","text":"VLDB 2024 An Efficient Transfer Learning Based Configuration Adviser for Database Tuning 动机评估配置需要资源和时间来运行工作负载，这是优化数据库时的主要成本。给定一个调优任务，搜索空间的构造和搜索优化器的选择是影响调优效率的主要因素。虽然先前的研究试图通过选择重要的旋钮和开发高级搜索优化器，在实践中应用先前研究的调优系统来提高调优效率，但仍然存在以下问题和挑战： 无效的大搜索空间 选择重要的knob可以加速调优过程。但是全局重要旋钮的静态选择并不适用于各种工作负载，而为了选择特定于工作负载的重要旋钮在之前的实践中需要在不同的配置上执行许多目标工作负载。不幸的是，这种方法是高成本的。针对每个旋钮选择适当的值范围是有用的。这是因为探索默认范围的空间是资源密集型的，浪费了大量不可行区域的实验；并且有效的范围可能因为工作负载的不同而不同，手册中的默认值范围是广泛的，而不是针对特定的工作负载设置的。 不同调优任务的固定搜索优化器 尽管存在各种的搜索优化器，但是没有一个搜索优化器可以主导所有的调优任务。简单的启发式方法不能捕获调优任务（tuning task）与不同优化器性能之间的关系，无法推荐最佳搜索优化器。 贡献OpAdviser利用从之前调优任务中收集的历史数据和构建的bechmark数据来自动构建紧凑的搜索空间并为给定任务选择适当的搜索优化器。 通过从类似的历史任务中提取有前途的几何图形来获得workload-specific的重要旋钮及其有效范围（迁移学习） 捕获任务特征与候选优化器性能排名的关系来推荐合适的搜索优化器（数据驱动的方法） 结构总览 组件： controller 通过与终端用户和数据库实例交互来控制调优过程 data repository 存储不同的调优任务的历史observations（${ \\theta_j^i,f(\\theta_j^i,w_i) }, i^{th}$任务，$w_i$目标调优任务），obsevations包含所有的可配置旋钮，保证其维度相同 space constructor 生成一个紧凑的搜索空间 optimizer adviser 选择最合适的搜索优化器 configuration generator 生成最优的配置 工作流程 用户提供调优目标，调优预算，数据库实例，目标工作负载，开始迭代调优 controller在云数据库上应用新的配置，执行工作负载并获得数据库性能 存储observation到data repository 使用目标和历史任务的observations，space constructor识别相似的任务并通过组合有希望的范围构建一个紧凑的搜索空间 optimizer adviser 分析搜索空间和历史观测，提取目标任务的meta-feature，输入meta-ranker（根据基准数据预训练获得）。meta-ranker预测optimizers的性能排名并推荐排名靠前的 根据搜索空间和推荐的搜索优化器，在configuration generator推荐有希望的配置并传递到controller 迭代2-6，直到预算耗尽，获得最优的配置，返回给用户 搜索空间的构建为了识别出基于特定工作负载的重要旋钮和旋钮值范围，同时减少目标工作负载的运行，我们借助相似的历史任务，去获得紧凑的搜索空间。同时，该紧凑搜索空间是考虑任务相似性相应地动态调整区域，已避免对搜索空间的过度修剪。输入：之前任务(source task)的观测，目标任务(target task)输出：紧凑的目标搜索空间 相似任务识别不同调优任务的历史观测值可以提供有价值的信息。这是由于相似的工作负载运行在不同的硬件环境下可能共享与硬件无关的旋钮的常见范围；不同的工作负载也可能共享相同的不好的搜索区域。因此，对于给定的目标任务，检查相似的历史任务可以揭示类似的有希望的区域。本文用目标任务和源任务在不同配置下是否具有相似的性能排名（基于目标观测值的一致排名对比率_ratio of concordant ranking pairs_$S(i,t)$）来获得相似性。$f^{‘}$:性能模型(在离线阶段用随机森林训练获得) ；$F(i,t)$表示目标任务和$w_i$源任务之间具有的一致排名对的数量；$H^t$表示目标任务下的observations数量$F(i,t)$的计算：在目标任务的observation下，目标任务的性能和在$f^{‘}$预测的性能进行比较，获得排名一致的observation数量。在每一次迭代中，计算数据资源库中的所有源任务与当前目标任务的相似度，过滤掉相似度s低于0.5的源任务。 有效区域提取如何通过考虑源任务与目标任务的相似性来提取有效区域？下面公式定义从第i个任务中提取到的最小的有意义的值范围G：下面公式表示的大小，应该保证其尽可能小。K1表示连续的旋钮，K2表示离散的旋钮构建G：（1）当观测到的性能大于$f^i_b$，将该观测到的配置加入到G中；（2）当随机采样到的预测性能大于$f^i_b$，加入G$f^i_b$由如下公式进行计算。当目标任务与当前源任务相似度高的时候，$f^i_b$趋近于$f_{best}^i$，使得提取的区域紧凑；当当目标任务与当前源任务相似度低的时候，提取的区域大，防止对搜索空间的过度裁剪。 重要旋钮选择策略基于历史观测，利用SHAP（通过解释配置之间的性能变化来衡量功能的重要性）识别重要的旋钮。丢弃仅仅表现具有负贡献的旋钮，其旋钮的有效范围设置为0。 多数加权表决最后一步是生成目标搜索空间，包括重要的旋钮及其值范围。本文采用多数加权投票策略来汇总候选任务的建议。对第i个任务分配一个与其目标任务相似度成正比的权重：。选择重要旋钮：一个旋钮是否丢弃，取决于多数源任务是否同意。这种方法不需要设置重要旋钮的数量这个超参数。确定旋钮的值范围：对每个保留的旋钮，枚举提取的有效范围，保留多数投票保留的部分。 进一步避免负迁移 将目标任务作为选民，使用当前目标观测生成参考有效区域。在计算目选民的权重时，使用下面的公式，在未见过的配置上测试泛化能力。 其中，是根据$H^t$拟合的预测模型，并排除$\\theta_j$上的observation。这种留一模型能够更好地泛化到未见过的配置。OpAdviser使用第四次迭代中的历史任务来暖启动空间建议，从第6次迭代开始引入目标模型。这一步可以解决当没有历史观测数据时的冷启动问题。例如，寻求优化自己的应用程序的小型终端用户在离线数据收集存在挑战，他们在开始调优的时候没有历史数据。当_target concordant ordering ratio_超过0.5的时候，OpAdviser通过基于目标观测提取有效区域来构建搜索空间。 从所有的候选的任务中采集k个任务并不进行替换，而不是利用全部的任务。这为目标空间的生成增加随机性，避免陷入局部最优。 搜索优化器推荐依赖于一般启发式方法进行搜索优化器的选择是有挑战且不可靠的。例如从GA转换到DDPG的迭代次数的确定是很复杂的。另外，启发式方法依赖于人类经验，这可能无法涵盖具有不同特征的各种调优任务。本文提出一种数据驱动的方法，利用机器学习模型来调整任务选择。通过预训练模型，OpAdviser利用从不同优化器的运行历史中提取的知识，直接生成预测，而无需在当前任务上实际运行候选优化器。 元特征提取对每个调优任务，提取以下元特征。这些元特征表征调优任务，并且可以影响不同搜索优化器的调优性能。 空间特征 旋钮的数量，搜索空间的大小，连续型和离散型旋钮的比例 响应面特征 响应面的差异主要来源于不同的工作负载和硬件环境。采用一个相似向量（包含当前的任务和之前每个任务的一致排名对的比例S(i,k)） 调优过程特征 使用当前迭代次数作为特征 离线数据生成训练模型，需要数据来演示不同候选优化器在特定条件下的表现，但是对所有潜在的调优任务执行详细的测试成本是高昂的。本文采用主动学习技术来选择样本进行测试和标记，以用更少的测试工作来有效收集数据，并且获得相对重要的数据。首先通过变换搜索空间和响应特征生成一组候选的调优任务；我们迭代选择不确定性最高的任务进行测试。例如使用主动学习指标classification margin，余量margin最小的样本代表最大的不确定性。此过程持续进行，直到达到所需的决策裕度水平或测试预算耗尽。 元排名器构建利用收集到的数据，我们继续构建学习模型，即元排名器（meta-ranker）输入：任务的元特征，两个候选的搜索优化器输出：在给定任务上候选优化器相对的表现排名 具体实现本文采用的LambdaMART，使用梯度提升决策树，优化成对的损失函数，去捕捉不同调优场景下的优化器的相对性能元排名器训练过程中的数据结构化为，m表示元特征，$o_i$表示独热编码的候选优化器，I表示一个标识符，当$o_i$的性能超过$o_j$时，I为1，否则为0。 在线阶段OpAdviser从目标任务提取元特征，和候选的一对优化器输入到元排名器，推荐排名靠前的优化器。 优点这个方法能够考虑任务的特征去获得优化器的性能。与预测最佳优化器的直接分类模型相比，通过考虑成对性能可以提取更多信息。此外，与回归模型相比，meta-ranker仅需要优化器对之间的比较，并且可以更好地处理噪声数据和不同尺度的数据。 实验 使用吞吐量作为最大的目标，比较200次迭代（每个迭代中3分钟的压力测试） 4个工作负载：Sysbench (RO), Sysbench (WO), Sysbench (RW), Twitter 候选的优化器：MBO, SMAC, DDPG, GA 数据存储库：为meta-ranker生成训练数据，通过调整调优旋钮产生390个不同的空间，变换9个工作负载，一共生成3510调优任务。从中标记48个任务，记录在不同的调优迭代和4个候选优化器下的性能观测。为了保证比较的公平，将保留数据存储库中存在的目标工作负载的任何观察结果。 比较与LlamaTune、Hunter、DB-BERT、ResTune、OtterTune、CDBTune、SMAC比较，OpAdviser能够在一半的调优预算中实现相同的最优的吞吐量。 开销分析在离线训练阶段，一个任务的表及过程消耗2400分钟（4x200x3，一次迭代3分钟压力测试，一共200次迭代）。标记48个调优任务，一共花费20天（4个数据库实例并行）在线阶段，OpAdviser虽然在算法上需要更多的时间（秒级别），但是借助历史任务观测构建一个紧凑的搜索空间，能够识别具有较少目标工作负载运行的更好配置。 泛化性分析在不同数据大小和硬件设置下，实验OpAdviser的性能","link":"/2024/04/21/VLDB-2024-OpAdviser/"},{"title":"SIGMOD 2023 GPTuner","text":"这是一篇关于GPT增强数据库中旋钮调优任务的论文https://arxiv.org/abs/2311.03157 MotivationExisting automatic tuning systems still incur significant tuning costs or only yields sub-optimal performance.这主要是因为： ignore the extensive domain knowledge available (e.g., DBMS manuals and forum discussions) only rely on the runtime feedback of benchmark evaluations to guide the optimization they utilize the domain knowledge in a limited way LLM is a notable step forward, but not adequate yet. since domain knowledge typically comes in the form of DBMS documents and discussions from DBMS forums, it involves a complex and lengthy workflow to process such heterogeneous and noisy knowledge: the brittle nature of LLM (i.e. small modifications to the prompt can cause large variations in the model outputs) and the hallucination problem of LLM(i.e., LLM generates answers that seem correct but are factually false) Even if structured knowledge is developed, its integration into the optimization process is deficient将结构化的数据整合进入BO流程存在问题。如果不修改标准工作流程，可以使用的信息是手册推荐的范围约束。但是如果利用建议值和特殊值这两个考虑的内容，则需要创新的优化框架。 Contributions: leverages domain knowledge extensively automatically to optimize search space enhance the runtime feedback-based optimization process k1 = xx k2 = xx k3 =xx k4 = xx 100 &lt; k1 &lt; 1000 k1 = 100 , k1 =200, k1 =300 ,k1=400 k1 = 256 Deductive Beam Search: Decoding Deducible Rationale for Chain-of-Thought Reasoning Self-RAG Chain of Thought Tree of Thought reflection react (agent)ReAct: Synergizing Reasoning and Acting in Language Models Lora 7B 48G Overview❶ User provides the DBMS to be tuned (e.g., PostgreSQL or MySQL), the target workload, and the optimization objective (e.g., latency or throughput).❷ GPTuner collects and refines the heterogeneous knowledge from different sources (e.g., GPT-4, DBMS manuals and web forums) to construct Tuning Lake, a collection of DBMS tuning knowledge.❸ GPTuner unifies the refined tuning knowledge from Tuning Lake into a** structured view** accessible to machines (e.g., JSON).❹ GPTuner reduces the search space dimensionality by selecting important knobs to tune❺ GPTuner optimizes the search space in terms of** the value range for each knob** based on structured knowledge.❻ GPTuner explores the optimized space via a novel Coarse-to-Fine Bayesian Optimization framework❼ identifies satisfactory knob configurations within resource limits (e.g., the maximum optimization time or iterations specified by users). C1 unify a structured view of the heterogeneous domain knowledge while balancing a trade-off between cost and quality.=&gt;使用LLM收集和提炼异构信息，并结构化表示 Knowledge Preparation data ingestion从资源（web forums、GPT、DBMS册）中收集tuning knowledge（） data cleaning建模为二元分类问题，采用LLM解决针对一个knob，给出候选的tuning knowledge和DBMS的system view；在提示中给出几个例子=&gt;LLM评估tuning knowledge和system view是否冲突，放弃冲突的知识 data integration使用LLM，根据信息源的可靠性，手动设置优先级（Manual&gt;Web&gt;LLM），进行整合一个knob的多条tuning信息 data correction上步由LLM完成的summary任务，可能与事实不符。使用LLM进行事实一致性检查（prompt: the summarization and the source contents）=&gt; 不一致，提示GPT重新生成摘要，再次提交摘要和源内容（Mannual、Web、GPT）给GPT，直到GPT识别没有问题 Knowledge Transformation（data extraction） Attributes：suggested_values( good staring points for new scenario ), min_value, max_value(默认值过宽，优化过程复杂化，带来系统奔溃的风险 ) and special_value（会导致DBMS不同的行为） Attribute Values：Prompt Ensemble Algorithm we decompose the transformation task into two subtasks of extracting (1) suggested_values, min_value, max_value and (2) special_value, respectively. Next, we prepare the prompt including examples following the template in Figure 9 for each subtask. vary the prompts by changing the examples provided for few-shots learning. 由于LLM的脆弱和幻觉问题，对每个prompt，从手工构建的K(10)个examples随机选取n()3个 aggregate the results via a majority vote strategy. 对每个属性选择频率最高的值 C2 integrate the knowledge into the optimization process.使用结构化的数据S： design a workload-aware and training-free knob selection strategyMotivation: Existing approaches rely on ML-based algorithms to select important knobs and this requires hundreds to thousands of evaluations on DBMS under different workloads and configurations使用LLM模拟DBA的旋钮选择： System-Level selects knobs based on the specific DBMS product. 提示GPT-4根据DBMS产品推荐调整旋钮 Workload-Level selects knobs based on the workload type. 根据workload类型和优化目标 Query-Level selects knobs based on the bottleneck of queries.在提示中包含每个查询的执行计划，LLM选择瓶颈感知旋钮 Knob-Level complements interdependent knobs to a given target knob set. develop a search space optimization technique considering the value range of each knob,对每个维度的数据，舍弃无意义的区域，突出有前景的空间，考虑特殊情况 Region DiscardWe utilize min_value and max_value to discard some regions for the following cases： The regions are unlikely to result in promising performance. The regions could seize too many system resources.对资源相关的knob The regions that can make the DBMS crash.对资源相关的knob Tiny Feasible Space ？apply a set of multiplicators for each **suggested value V **of all numerical knobsconsidering the value range and calculating the multiplicators dynamicallyFor knob For knob 𝑘, we denote its maximum (minimum) value as 𝑈The choice of 𝑈 determines the deviation directionand 𝛽 controls the changing extends.Tiny Feasible Space 离散空间：() Virtual Knob ExtensionFor example, knob “lock_timeout”, with a value range from 0 to 2147483647, controls the maximum allowed duration of any wait for a lock. When it is set to zero, the timeout function is disabled and this makes “0” a special value. utilize Structured Knowledge to select which knobs have the special values add “virtual knobs” (control_knob, normal_knob and special_knob) for each knob with special value. control_knob为1/0分别表示special_knob(normal_knob)被激活 propose a Coarse-to-Fine Bayesian Optimization Framework to explore the optimized space本工作主要发现：将领域知识融入优化过程，迭代成本会大大降低现有的方法依赖于历史结果来使用良好的起点初始化，但是准备这些结果的成本很高并需要在硬件组件和软件版本的变化下进行重建。 the fist stage：BO只探索整个异构空间的离散子空间Tiny Feasible Space ten samples (𝑛 = 10) are generated by Latin Hypercube Sampling (LHS) from Tiny Feasible Space the samples are evaluated on DBMS (Line 3) and the surrogate model is initialized we explore Tiny Feasible Space with the BO algorithm for C iterations the second satge we bootstrap BO with the samples from the first stage we narrow down space P with the Region Discard technique we take into account the knobs with special values with the Virtual Knob Extension technique EXPERIMENTAL EVALUATIONbaseline: GPTuner is implemented with SMAC3 library and uses OpenAI completion API of GPT-4.We run three tuning sessions for each method, with each session consisting of **100 iterations **and each iteration requires a stress test for the target workload.For BO-based methods, we follow the setting of iTuned [12] and OtterTune [50] by **executing 10 configurations **generated by Latin Hypercube Sampling (LHS) [31] to initialize the surrogate model.For RL-based methods, we follow recent works [4, 48] and do not train the neural network since it is evaluated that the trained network suffers from over-fitting [57].","link":"/2024/04/22/SIGMOD-2023-GPTuner/"},{"title":"Hexo增加页面","text":"增加页面笔记 增加页面创建一个新的页面1$ hexo new &quot;My New Post&quot; 更多信息: Writing 运行1$ hexo server More info: Server 生成静态文件1$ hexo generate 更多信息: Generating 部署1$ 更多信息 More info: Deployment","link":"/2024/04/21/%E5%A2%9E%E5%8A%A0%E9%A1%B5%E9%9D%A2/"},{"title":"summary","text":"针对本次开源作业的总结 博客主题和选取原因我选择了Hexo的icarus主题作为生成博客的工具，其主要有以下原因： Hexo使用node.js，生成速度超快，几百个页面可以瞬间完成渲染。 无论是在本地测试还是部署到Github pages都十分方便 支持markdown的所有功能，还能整合多种插件，具有极强的可扩展性。 icarus是一个比较成熟的主题，可修改空间很大，可支持移动端，可以增加多种多样的功能且有文档支撑非常方便。 页面布局和设计思路首页分为三栏，分别展示作者信息，目录，归档，最新文章，标签统计信息，以及所有文章缩略的信息。 文章详情展示文章笔记，也包含发表时间，更新时间等信息 目录页 归档页 标签页 功能实现和技术选择 在windows11下进行 安装Hexo 首先需要安装nodejs和git，接着使用npm进行安装hexo的包1$ npm install hexo-cli -g 初始化一个博客项目12$ hexo init blog$ cd blog 启动服务默认端口为4000，即访问localhost:40001$ hexo server 选择安装主题可以在hexo.io下找到想要的模板，这里选择的模板是icarus 将选择的模板拉取到blog/themes目录下面 安装依赖并设置hexo的主题为icarus12$ npm install hexo-theme-icarus$ hexo config theme icarus 生成新的post.md文件1$ hexo new &quot;my post&quot; 启动服务1$ hexo server 部署到github blog仓库与远程仓库绑定 12$ git remote remove origin$ git remote add origin 你的仓库地址 安装部署插件 1$ npm install hexo-deployer-git --save 生成静态文件 1$ hexo g 部署到远程，修改_config.yml文件，并新建远程仓库，其名称为kxkllday.github.io 123456url: http://kxkllday.github.ioroot: /deploy: type: 'git' repo: https://github.com/kxkllday/kxkllday.github.io.git branch: main 部署 1$ hexo d 遇到的问题和解决办法图片显示异常，没有办法显示出来 安装相关插件1$ npm install hexo-asset-image --save 修改_config.yml配置1post_asset_folder: true 将图片存在与md文件同名的文件夹下面 首页一开始没有办法仅仅展示部分缩略信息在md文件在front-matter中使用如下代码分割开来需要展示在首页的缩略信息以及不展示的更多信息 1&lt;!-- more --&gt;","link":"/2024/04/22/summary/"}],"tags":[{"name":"配置","slug":"配置","link":"/tags/%E9%85%8D%E7%BD%AE/"},{"name":"旋钮调优","slug":"旋钮调优","link":"/tags/%E6%97%8B%E9%92%AE%E8%B0%83%E4%BC%98/"},{"name":"总结，配置","slug":"总结，配置","link":"/tags/%E6%80%BB%E7%BB%93%EF%BC%8C%E9%85%8D%E7%BD%AE/"}],"categories":[{"name":"论文阅读","slug":"论文阅读","link":"/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"},{"name":"配置","slug":"配置","link":"/categories/%E9%85%8D%E7%BD%AE/"}],"pages":[]}